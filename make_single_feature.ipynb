{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import gridspec\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "#import glob2\n",
    "\n",
    "from numba import jit\n",
    "import tables\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "import h5py\n",
    "#import hdf5storage\n",
    "import csv\n",
    "\n",
    "import deeplabcut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# READ X,Y and Likelihoods from a presaved CSV file\n",
    "   \n",
    "def load_csv(fname):\n",
    "    with open(fname, newline='') as csvfile:\n",
    "        data = list(csv.reader(csvfile))\n",
    "\n",
    "    labels = data[1]\n",
    "\n",
    "    # load values\n",
    "    data_array = np.array(data[3:])\n",
    "\n",
    "    # \n",
    "    #labels = ['fnose','f_leye','f_reye','f_lear','f_rear','f_',\n",
    "    #         'male_nose','male_left_ear','male_right_ear','male_base_of_tail',\n",
    "    #          'pup_shaved_nose','pup_shaved_left_ear','pup_shaved_right_ear','pup_shaved_base_of_tail',\n",
    "    #          'pup_noshave_nose','pup_noshave_left_ear','pup_noshave_right_ear','pup_noshave_base_of_tail'             \n",
    "    #         ]\n",
    "    \n",
    "    labels = labels[1:]\n",
    "    \n",
    "    traces = []\n",
    "    traces_nan = []\n",
    "    for idx in range(1,len(labels)-1,3):\n",
    "        temp = data_array[1:,idx:idx+3]\n",
    "        idx1 = np.where(temp=='')[0]\n",
    "        temp[idx1]=0\n",
    "        temp = temp.astype(np.float)# np.array(temp)\n",
    "\n",
    "        # replace low likelihoods with median\n",
    "        likelihoods = temp[:,2]\n",
    "        idx2 = np.where(likelihoods<0.8)[0]\n",
    "        temp[idx2,0]=np.median(temp[:,0])\n",
    "        temp[idx2,1]=np.median(temp[:,1])\n",
    "        traces.append(temp.copy())\n",
    "        \n",
    "        temp[idx2,0]=np.nan\n",
    "        temp[idx2,1]=np.nan\n",
    "        traces_nan.append(temp.copy())\n",
    "\n",
    "    return traces, labels, traces_nan\n",
    "\n",
    "def load_csv_data(data_all):\n",
    "    traces = np.array(data_all[0])\n",
    "    #print (traces[0].shape)\n",
    "    tracesx = []\n",
    "    tracesy = []\n",
    "    likelihoods = []\n",
    "\n",
    "    for k in range(0,len(traces),1):\n",
    "        tracesx.append(traces[k][:,0])\n",
    "        tracesy.append(traces[k][:,1])\n",
    "        likelihoods.append(traces[k][:,2])\n",
    "\n",
    "    likelihoods = np.array(likelihoods)\n",
    "    tracesx = np.array(tracesx)\n",
    "    tracesy = np.array(tracesy)\n",
    "    print (\"tracex: \", tracesx.shape)\n",
    "    print (\"tracey: \", tracesy.shape)\n",
    "    print (\"likelihood: \", likelihoods.shape)\n",
    "        \n",
    "    return tracesx, tracesy, likelihoods\n",
    "\n",
    "# MAKE VIDOES + LABELS \n",
    "\n",
    "# Robust outlier detection function to crop some of the DLC errors;\n",
    "def reject_outliers(data, m = 2.):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/mdev if mdev else 0.\n",
    "    return data[s<m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracesx:  (56, 89989)\n",
      "DONE Loading traces and likelihoods\n"
     ]
    }
   ],
   "source": [
    "# load a csv file; \n",
    "\n",
    "# OLD CSV DATA\n",
    "if False:\n",
    "    csv_fname = '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_bx.csv'\n",
    "    data_all = load_csv(csv_fname)\n",
    "    tracesx, tracesy, likelihoods = load_csv_data(data_all)\n",
    "# NEW INFERENCE FIXED DATA\n",
    "else:\n",
    "    # alterantive data:\n",
    "    csv_fname= '/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_bx_inference_fixed.npz'\n",
    "    traces = np.load(csv_fname)\n",
    "    tracesx = traces['tracesx']\n",
    "    tracesy = traces['tracesy']\n",
    "    likelihoods = traces['probs']\n",
    "    print (\"tracesx: \", tracesx.shape)\n",
    "\n",
    "    \n",
    "#traces_all = np.stack((np.stack((tracesx,tracesy)),likelihoods))\n",
    "print (\"DONE Loading traces and likelihoods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n",
      "0 / 89989\n",
      "5000 / 89989\n",
      "10000 / 89989\n",
      "15000 / 89989\n",
      "20000 / 89989\n",
      "25000 / 89989\n",
      "30000 / 89989\n",
      "35000 / 89989\n",
      "40000 / 89989\n",
      "45000 / 89989\n",
      "50000 / 89989\n",
      "55000 / 89989\n",
      "60000 / 89989\n",
      "65000 / 89989\n",
      "70000 / 89989\n",
      "75000 / 89989\n",
      "80000 / 89989\n",
      "85000 / 89989\n",
      "total nans: [31993, 44883, 64551, 77055]\n",
      "DONE Loading mean traces\n"
     ]
    }
   ],
   "source": [
    "# Save median/single feature trackelts and likelihoods\n",
    "# initialize start and ends of video to be analyzed\n",
    "start = 0\n",
    "end = tracesx.shape[1]\n",
    "#end = 1000\n",
    "\n",
    "tracesx_mean =[]\n",
    "tracesy_mean =[]\n",
    "likelihoods_mean =[]\n",
    "threshold = 0.01\n",
    "\n",
    "total_nans = [0]*4\n",
    "\n",
    "for k in range(start,end,1):    \n",
    "    if k%5000==0:\n",
    "        print (k, \"/\", end)\n",
    "        \n",
    "    tracesx_mean.append([])\n",
    "    tracesy_mean.append([])\n",
    "    # PLOT MEAN FEATURE\n",
    "    for p in range(0, tracesx.shape[0], 14):\n",
    "        l = likelihoods[p:p+14,k]\n",
    "        idx = np.where(l<threshold)[0]\n",
    "        #print(idx.shape)\n",
    "\n",
    "        traces_local = tracesx[p:p+14,k]\n",
    "        traces_local = np.delete(traces_local, idx)\n",
    "        \n",
    "        # remove nans from data\n",
    "        idx_nan = np.where(np.isnan(traces_local)==True)[0]\n",
    "        traces_local = np.delete(traces_local, idx_nan)\n",
    "\n",
    "        # reject outliers\n",
    "        traces_local = reject_outliers(traces_local, m = 4)\n",
    "\n",
    "        x = np.nanmedian(traces_local)\n",
    "        \n",
    "        \n",
    "        traces_local = tracesy[p:p+14,k]\n",
    "        traces_local = np.delete(traces_local, idx)\n",
    "\n",
    "        # remove nans from data\n",
    "        idx_nan = np.where(np.isnan(traces_local)==True)[0]\n",
    "        traces_local = np.delete(traces_local, idx_nan)\n",
    "\n",
    "        # reject outliars\n",
    "        traces_local = reject_outliers(traces_local, m = 4)\n",
    "        y = np.nanmedian(traces_local)\n",
    "        #print (\"XY: \", x,y)\n",
    "        tracesx_mean[k].append(x)\n",
    "        tracesy_mean[k].append(y)\n",
    "        \n",
    "        if np.isnan(x) or np.isnan(y):\n",
    "            total_nans[p//14]+=1\n",
    "\n",
    "tracesx_mean = np.array(tracesx_mean)\n",
    "tracesy_mean = np.array(tracesy_mean)\n",
    "\n",
    "print (\"Total nans (missing frames) for each animal: \", total_nans)\n",
    "\n",
    "print (\"DONE Loading mean traces\")\n",
    "np.savez(csv_fname[:-4]+'_single_feature_traces_WITH_INFERENCES.npz', \n",
    "         tracesx=tracesx_mean,\n",
    "         tracesy=tracesy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nans (missing frames) for each animal:  [31993, 44883, 64551, 77055]\n",
      "DONE Loading mean traces\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE Loading mean traces\n"
     ]
    }
   ],
   "source": [
    "print (\"DONE Loading mean traces\")\n",
    "np.savez('/media/cat/4TBSSD/dan/march_2/madeline_dlc/march_16/2020-3-16_12_57_12_418305_compressed/2020-3-16_12_57_12_418305_compressedDLC_resnet50_madeline_july2Jul2shuffle1_100000_bx_single_feature_traces_WITH_INFERENCE.npz', \n",
    "        tracesx=tracesx_mean,\n",
    "        tracesy=tracesy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[284.815     nan     nan     nan]\n",
      " [285.203     nan     nan     nan]\n",
      " [285.049     nan     nan     nan]\n",
      " ...\n",
      " [    nan     nan     nan     nan]\n",
      " [    nan     nan     nan     nan]\n",
      " [    nan     nan     nan     nan]]\n"
     ]
    }
   ],
   "source": [
    "print (tracesx_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data\n",
    "total=[1964, 4534, 5890, 9721]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11851315 0.27359401 0.35541878 0.58659184]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print (np.array(total)/16572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
