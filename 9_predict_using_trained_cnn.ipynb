{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "########### LOAD PKGS ##############\n",
    "####################################\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "#%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "########### MAKE DATA LOADER FUNCTION ###########\n",
    "#################################################\n",
    "\n",
    "# FUNCTION REQUIRED FOR TORCH (?) ALSO FOR RESNET fixed sizes\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.46, 0.48, 0.51], [0.32, 0.32, 0.32])\n",
    "    ])\n",
    "\n",
    "# DATA LOADER AND RANDOMIZER FUNCTION\n",
    "def make_trainloader(train_data, \n",
    "                     vals, \n",
    "                     batch_size,\n",
    "                     randomize=True):\n",
    "    \n",
    "    # RANDOMIZE DATA EVERYTIME THIS IS CALLED\n",
    "    if randomize:\n",
    "        idx = np.random.choice(np.arange(vals.shape[0]),\n",
    "                         vals.shape[0],replace=False)\n",
    "        # REARANGE DATA BASED ON RANDOMIZATION FLAG\n",
    "        train_data = train_data[idx]\n",
    "        vals = vals[idx]\n",
    "    else:\n",
    "        idx = np.arange(vals.shape[0])\n",
    "    \n",
    "\n",
    "    # Compute number of batches\n",
    "    n_batches = train_data.shape[0]//batch_size\n",
    "\n",
    "    # make trainign data plus labels\n",
    "    data_train = []\n",
    "    vals_train = []\n",
    "    for k in range(0,n_batches*batch_size,batch_size):\n",
    "        data_train.append(train_data[k:k+batch_size])\n",
    "        vals_train.append(vals[k:k+batch_size])\n",
    "\n",
    "    # \n",
    "    print (\"# batches: \", n_batches)\n",
    "        \n",
    "    # RATIO OF DATA SPLIT BETWEEN TRAIN AND TEST\n",
    "    split = 0.8\n",
    "    \n",
    "    trainloader = zip(data_train[:int(len(data_train)*split)],\n",
    "                      vals_train[:int(len(data_train)*split)])\n",
    "    \n",
    "    testloader = zip(data_train[int(len(data_train)*split):],\n",
    "                      vals_train[int(len(data_train)*split):])\n",
    "\n",
    "    return trainloader, testloader, n_batches\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function to load images and format for ResNet (n_images, rgb, width, height)\n",
    "def load_data(root_dir, max_count=1E10):\n",
    "    \n",
    "    # TODO: remove RGB EVENTUALLY; Find RESNET50 GREY\n",
    "    # make array to load data from 4 classes\n",
    "    data_loaded = np.zeros((0,3,200,200),'uint8')\n",
    "    vals = []\n",
    "    \n",
    "    # LOAD MONOCROME DATA, USUALLY GREEN CHAN\n",
    "    if False:\n",
    "        for k in range(4):\n",
    "            temp = np.repeat(np.load(root_dir+'/'+str(k)+'.npy')[None],3,axis=0).transpose(1,0,2,3)\n",
    "            data_loaded = np.vstack((data_loaded,temp))\n",
    "            vals.extend(np.zeros(temp.shape[0],'int32')+k)\n",
    "    \n",
    "    # LOAD RGB DATA (but NOTE THAT SECONDARY CHANS ARE messy)\n",
    "    if False:\n",
    "        for k in range(4):\n",
    "            temp = np.load(root_dir+'/'+str(k)+'.npy').transpose(0,3,1,2)\n",
    "            print (temp.shape)\n",
    "            data_loaded = np.vstack((data_loaded,temp))\n",
    "            vals.extend(np.zeros(temp.shape[0],'int32')+k)\n",
    "\n",
    "    # LOAD RGB DATA, COPY GREEN CHAN TO EVERYTHING ELSE\n",
    "    if True:\n",
    "        green_chan = 1\n",
    "        max_trials = max_count\n",
    "        for k in range(4):\n",
    "            temp = np.load(root_dir+'/'+str(k)+'.npy').transpose(0,3,1,2)[:,1]\n",
    "            temp = np.repeat(temp[:,None],3,axis=1)\n",
    "            \n",
    "            if (temp[0,0]-temp[0,1]).sum()!=0:\n",
    "                print (\"BREAK ERROR\")\n",
    "                break\n",
    "                \n",
    "            idx = np.random.choice(np.arange(temp.shape[0]),\n",
    "                                   max_trials,replace=False)\n",
    "            \n",
    "            temp = temp[idx]\n",
    "            print (temp.shape)\n",
    "            data_loaded = np.vstack((data_loaded,temp))\n",
    "            vals.extend(np.zeros(temp.shape[0],'int32')+k)\n",
    "\n",
    "    # convert lables to torch tensors\n",
    "    vals = torch.tensor(vals, dtype=torch.long)\n",
    "\n",
    "    # TRANSFORM DATA AS REQUIRED BY RESNET (?)\n",
    "    train_data = []\n",
    "    from tqdm import trange\n",
    "    for k in trange(vals.shape[0]):\n",
    "        temp2 = train_transforms(data_loaded[k].transpose(1,2,0))\n",
    "        train_data.append(temp2)  #THIS CAN BE DONE FASTER\n",
    "\n",
    "    all_data = torch.stack(train_data)\n",
    "    print (\"Train data final [# samples, RGB, width, height]: \", all_data.shape)\n",
    "\n",
    "    return all_data, vals\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# same as above but for single images\n",
    "def cnn_proceprocess_directory(root_dir, \n",
    "                               save_formated_data=False):\n",
    "    \n",
    "    \n",
    "    max_count = 1E10\n",
    "    \n",
    "    import glob\n",
    "    \n",
    "    # TODO: remove RGB EVENTUALLY; Find RESNET50 GREY\n",
    "    # make array to load data from 4 classes\n",
    "    \n",
    "#     fname_save = os.path.join(root_dir,\"data_formated.npz\")\n",
    "    \n",
    "#     if os.path.exists(fname_save)==False:\n",
    "\n",
    "    # find all images in directory saved as .npz files each\n",
    "    fnames = np.sort(glob.glob(root_dir + '/*.npz'))\n",
    "\n",
    "    # LOAD RGB DATA, COPY GREEN CHAN TO EVERYTHING ELSE\n",
    "    green_chan = 1\n",
    "    max_trials = max_count\n",
    "    data_loaded = [] #np.zeros((0,3,200,200),'uint8')\n",
    "    vals = []\n",
    "    frame_ids = []\n",
    "    for fname in fnames:\n",
    "        temp = np.load(fname)['frame']\n",
    "        \n",
    "        if len(temp.shape)==2:\n",
    "            temp = np.repeat(temp[:,:,None],3,axis=2)\n",
    "        if temp.shape[0]!=200:\n",
    "            print ('wrong size: ', temp.shape)\n",
    "\n",
    "        data_loaded.append(temp)\n",
    "\n",
    "        #\n",
    "        frame_id = int(os.path.split(fname)[1].replace('frame_','')[:7])\n",
    "        frame_ids.extend(frame_id)\n",
    "    \n",
    "    #\n",
    "    frame_ids = np.array(frame_ids)\n",
    "    \n",
    "    \n",
    "    # make stack of images\n",
    "    data_loaded=np.array(data_loaded)\n",
    "    print (\"data loaded: \", data_loaded.shape)\n",
    "    # shuffle data; not sure this is needed;\n",
    "    idx = np.random.choice(np.arange(data_loaded.shape[0]),\n",
    "                           data_loaded.shape[0],replace=False)\n",
    "\n",
    "    data_loaded = data_loaded[idx]\n",
    "\n",
    "\n",
    "    # save track id: \n",
    "    track_id = os.path.split(root_dir)[1]\n",
    "    \n",
    "    # convert lables to torch tensors\n",
    "\n",
    "    # TRANSFORM DATA AS REQUIRED BY RESNET (?)\n",
    "    train_data = []\n",
    "    from tqdm import trange\n",
    "    for k in trange(data_loaded.shape[0]):\n",
    "        #temp2 = train_transforms(data_loaded[k].transpose(1,2,0))\n",
    "        temp2 = train_transforms(data_loaded[k])\n",
    "        train_data.append(temp2)  #THIS CAN BE DONE FASTER\n",
    "\n",
    "    all_data = torch.stack(train_data)\n",
    "    #all_data = np.array(train_data)\n",
    "    #print (\"Train data final [# samples, RGB, width, height]: \", all_data.shape)\n",
    "\n",
    "    #\n",
    "    track_ids = np.zeros(frame_ids.shape[0],'int32')+track_id\n",
    "\n",
    "        \n",
    "    if save_formated_data:\n",
    "        np.savez(fname_save,\n",
    "            all_data = all_data,\n",
    "            track_ids=track_ids,\n",
    "            frame_ids = frame_ids)\n",
    "        \n",
    "#     else:\n",
    "#         data = np.load(fname_save)\n",
    "#         all_data = torch.from_numpy(data['all_data'])\n",
    "        \n",
    "        \n",
    "#     #all_data = all_data)\n",
    "#     #vals = torch.tensor(vals, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "    return all_data, track_id, frame_ids\n",
    "\n",
    "# DATA LOADER AND RANDOMIZER FUNCTION\n",
    "def make_testloader(train_data, \n",
    "                    batch_size,\n",
    "                    randomize=False):\n",
    "    \n",
    "    # RANDOMIZE DATA EVERYTIME THIS IS CALLED\n",
    "    if randomize:\n",
    "        idx = np.random.choice(np.arange(vals.shape[0]),\n",
    "                         vals.shape[0],replace=False)\n",
    "        # REARANGE DATA BASED ON RANDOMIZATION FLAG\n",
    "        train_data = train_data[idx]\n",
    "\n",
    "    # Compute number of batches\n",
    "    n_batches = train_data.shape[0]//batch_size\n",
    "    if (train_data.shape[0]/batch_size)!= train_data.shape[0]//batch_size:\n",
    "        n_batches+=1\n",
    "\n",
    "    # make test data\n",
    "    data_predict = []\n",
    "    for k in range(0,n_batches*batch_size,batch_size):\n",
    "        data_predict.append(train_data[k:k+batch_size])\n",
    "\n",
    "    # \n",
    "                      \n",
    "    return data_predict, n_batches\n",
    "\n",
    "\n",
    "\n",
    "def plot_bars(predictions, \n",
    "              confidence,\n",
    "              test_data):\n",
    "    \n",
    "    clrs = ['red','blue','cyan','green']\n",
    "    names = ['female','male','pup1 (shaved)','pup2 (unshaved)']\n",
    "\n",
    "    import matplotlib.patches as mpatches\n",
    "    import matplotlib.gridspec as gridspec\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    G = gridspec.GridSpec(4, 4)\n",
    "\n",
    "    # PLOT BAR GRAPHS FOR ALL PREDICTIONS\n",
    "    axes_1 = plt.subplot(G[:1, 0])\n",
    "    plt.title(\"All predicted labels\")\n",
    "    bins = np.arange(-0.5, 4.5, 1)\n",
    "    y = np.histogram(predictions, bins = bins)\n",
    "    for k in range(4):\n",
    "        plt.bar(y[1][k], y[0][k], 0.9, color=clrs[k])\n",
    "    \n",
    "    # add legend\n",
    "    handles, labels = axes_1.get_legend_handles_labels()\n",
    "    for k in range(4):\n",
    "        patch = mpatches.Patch(color=clrs[k], label=names[k])\n",
    "        handles.append(patch) \n",
    "    plt.legend(handles=handles, loc='upper center')\n",
    "    \n",
    "    \n",
    "    # PLOT BAR GRAPHS - THRESHOLD ON CONFIDENCe\n",
    "    axes_1 = plt.subplot(G[1:2, 0])\n",
    "    plt.title(\"Only high confidence labels\")\n",
    "    bins = np.arange(-0.5, 4.5, 1)\n",
    "    \n",
    "    threshold = 0.9\n",
    "    idx_high_conf = np.where(confidence>threshold)[0]\n",
    "    predictions_high_confidence = predictions[idx_high_conf]\n",
    "    \n",
    "    y_high_conf = np.histogram(predictions_high_confidence, bins = bins)\n",
    "    for k in range(4):\n",
    "        plt.bar(y_high_conf[1][k], y_high_conf[0][k], 0.9, color=clrs[k])\n",
    "    \n",
    "    # add legend\n",
    "    handles, labels = axes_1.get_legend_handles_labels()\n",
    "    for k in range(4):\n",
    "        patch = mpatches.Patch(color=clrs[k], label=names[k])\n",
    "        handles.append(patch) \n",
    "    plt.legend(handles=handles, loc='upper center')\n",
    "    \n",
    "    \n",
    "    # MAKE IMAGE PLOTS\n",
    "    max_id = np.argmax(y[0])\n",
    "    print (\"Main animal \", names[max_id])\n",
    "    \n",
    "    examples =[]\n",
    "    example_ids = []\n",
    "    for p in range(4):\n",
    "        if p==max_id:\n",
    "            continue\n",
    "        example_ids.append(p)\n",
    "        idx = np.where(predictions==p)[0]\n",
    "        try:\n",
    "            if idx.shape[0]>=3:\n",
    "                frames = np.random.choice(idx, 3, replace=False)\n",
    "            else:\n",
    "                frames = np.random.choice(idx, 3)\n",
    "        except:\n",
    "            frames = [0,0,0]\n",
    "            \n",
    "        examples.append(frames)\n",
    "    \n",
    "    for k in range(3):\n",
    "        ctr = 0\n",
    "        frames = examples[k]\n",
    "        for p in range(3):\n",
    "            ax = plt.subplot(G[k,p+1])\n",
    "\n",
    "            # get image\n",
    "            temp = test_data[frames[ctr]].cpu().detach().numpy().transpose(1,2,0)\n",
    "            plt.imshow(temp)\n",
    "\n",
    "            plt.title(\"fr: \"+str(frames[ctr])+ \", \"+\n",
    "                     names[predictions[frames[ctr]]])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            ctr+=1\n",
    "            \n",
    "            if p==0:\n",
    "                plt.ylabel(\"examples \\n\"+str(names[example_ids[k]]))\n",
    "\n",
    "\n",
    "    # PLOT TIME\n",
    "    axes_2 = plt.subplot(G[3, :])\n",
    "    clr_out = []\n",
    "    for k in range(predictions.shape[0]):\n",
    "        clr_out.append(clrs[predictions[k]])\n",
    "\n",
    "    time = np.arange(predictions.shape[0])/25.\n",
    "    plt.scatter(time, \n",
    "             np.ones(predictions.shape[0]),\n",
    "             c=clr_out)\n",
    "    \n",
    "    # \n",
    "    clr_out = []\n",
    "    for k in range(predictions_high_confidence.shape[0]):\n",
    "        clr_out.append(clrs[predictions_high_confidence[k]])\n",
    "        \n",
    "    time_high_conf = idx_high_conf/25.\n",
    "    plt.scatter(time_high_conf, \n",
    "             np.ones(predictions_high_confidence.shape[0])+1,\n",
    "             c=clr_out)\n",
    "\n",
    "\n",
    "    plt.xlabel(\"Time (sec)\", fontsize=20)\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.yticks([])\n",
    "    plt.suptitle(\"CNN animal detected: \"+names[max_id] + \"(all frames) \"\n",
    "                 + str(round(np.max(y[0])/np.sum(y[0])*100,2))+\"% of total track\"\n",
    "                 \n",
    "                 + \"\\nCNN animal detected (high confidence predictoin only): \"+names[max_id] + \" \"\n",
    "                 + str(round(np.max(y_high_conf[0])/np.sum(y_high_conf[0])*100,2))+\"% of total track\"\n",
    "                 + \"\\n SLEAP tracklet # \" + selected_track \n",
    "                 + \" (# frames in track \" \n",
    "                 +str(predictions.shape[0])+\")\", fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "# \n",
    "def load_training_data_run_prediction(fname_track, \n",
    "                                      model,\n",
    "                                      device,\n",
    "                                      recompute=False):\n",
    "    \n",
    "    max_count=1E10\n",
    "    \n",
    "    # grab track_id\n",
    "    track_id = int(os.path.split(fname_track)[1])\n",
    "    \n",
    "    # prep save file;\n",
    "    fname_out = os.path.join(fname_track,\"predictions.npz\")\n",
    "    if os.path.exists(fname_out)==False:\n",
    "\n",
    "        # preformat data\n",
    "        #fname_formated = os.path.join(fname_track,\"data_formated.npz\")\n",
    "        #if os.path.exists(fname_formated)==False:\n",
    "        test_data, track_id, frame_ids = cnn_proceprocess_directory(fname_track)\n",
    "        #test_data = torch.from_numpy(all_data)\n",
    "                \n",
    "        # change model to evaluation mode to avoid batch normalization\n",
    "        model.eval()\n",
    "\n",
    "        # load the test data\n",
    "        test_loader, n_batches = make_testloader(test_data, \n",
    "                                                  batch_size=500)\n",
    "\n",
    "        print (\" # batches: \", len(test_loader), \"  shape : \", test_loader[0].shape)\n",
    "\n",
    "        predictions = []\n",
    "        output_array = []\n",
    "        for inputs in test_loader:\n",
    "            # load to device\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            n_trials = inputs.shape[0]\n",
    "\n",
    "            # PREDICT;\n",
    "            outputs = model(inputs)\n",
    "            output_array.extend(outputs.cpu().detach().numpy())\n",
    "\n",
    "            # get best predictions\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().detach().numpy())\n",
    "\n",
    "        predictions = np.array(predictions)\n",
    "        #print (\"predictions: \", predictions.shape, predictions[:10])\n",
    "\n",
    "        #probs = predictions \n",
    "        output_array = np.array(output_array)\n",
    "        #print (\"output array: \", output_array.shape)\n",
    "        sig_pred = 1 / (np.exp(-output_array))  # confidence map\n",
    "\n",
    "        confidence = []\n",
    "        for k in range(sig_pred.shape[0]):\n",
    "            confidence.append(sig_pred[k][predictions[k]])\n",
    "        confidence=np.array(confidence)\n",
    "        #print (\"confidence; \", confidence[:10])\n",
    "        \n",
    "        np.savez(fname_out,\n",
    "                 predictions=predictions,\n",
    "                 confidence=confidence,\n",
    "                 track_id=track_id,\n",
    "                 frame_ids=frame_ids)\n",
    "        \n",
    "    else:\n",
    "        data = np.load(fname_out)\n",
    "        predictions = data['predictions']\n",
    "        confidence = data['confidence']\n",
    "        \n",
    "    return predictions, confidence\n",
    "\n",
    "\n",
    "\n",
    "def initialize_resnet():\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                      else \"cpu\")\n",
    "    model = models.resnet50(pretrained=True)\n",
    "\n",
    "    # Not sure what this does\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Note sure what this does, effect on fc layer?\n",
    "    model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.2),\n",
    "                                     nn.Linear(512, 4),\n",
    "                                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "    # todo: look up this loss\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # todo: look up this optimizer\n",
    "    optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "\n",
    "    # move model to gpu\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(epochs, model):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print (\"epochs: \", epoch)\n",
    "\n",
    "        trainloader, testloader, n_batches = make_trainloader(all_data, \n",
    "                                                              vals, \n",
    "                                                              batch_size=500)\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "        n_trials=0\n",
    "        ctr=0\n",
    "        for inputs, labels in trainloader:\n",
    "            steps += 1\n",
    "            n_trials+= labels.shape[0]\n",
    "            #print (inputs.shape)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            last_inputs=torch.clone(inputs)\n",
    "            last_labels=torch.clone(labels)\n",
    "\n",
    "\n",
    "            # ZERO INit\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # PREDICT;\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "    #         if False:# ctr%10==0:\n",
    "    #             print (labels[:10])\n",
    "    #             print (preds[:10])\n",
    "    #             print ('')\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # track performance \n",
    "            if False:\n",
    "                # ON TRAIN DATA\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # evaluate results\n",
    "        if True:\n",
    "            n_trials=0\n",
    "            # test only on first train dataset\n",
    "            for inputs, labels in testloader:\n",
    "\n",
    "                n_trials+= labels.shape[0]\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if True:# ctr%10==0:\n",
    "                    print (\"labels: \", labels[:10])\n",
    "                    print (\"predictions: \", preds[:10])\n",
    "                    print ('')\n",
    "\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds.data == labels.data)\n",
    "\n",
    "                break\n",
    "\n",
    "        epoch_loss = running_loss / n_trials\n",
    "        epoch_acc = running_corrects / n_trials\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            ctr, epoch_loss, epoch_acc))\n",
    "\n",
    "\n",
    "        ###############################################\n",
    "        ############## SAVE MODEL #####################\n",
    "        ###############################################\n",
    "        if False:\n",
    "            root_dir = '/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/'\n",
    "            model_name = 'model.pt'\n",
    "\n",
    "            torch.save(model.state_dict(), root_dir+model_name)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.3.weight\", \"fc.3.bias\". \n\tUnexpected key(s) in state_dict: \"fc.2.weight\", \"fc.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6a4f228c32f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/model_100epoch_Green3Chan_cnn_training_30mins_data.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"fc.3.weight\", \"fc.3.bias\". \n\tUnexpected key(s) in state_dict: \"fc.2.weight\", \"fc.2.bias\". "
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "##### INIT MODEL AND LOAD SAVED MODEL (OPTIONAL) ##\n",
    "###################################################\n",
    "model = initialize_resnet()\n",
    "\n",
    "# load prev model params\n",
    "if False:\n",
    "    fname = '/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/model_100epoch_Green3Chan_cnn_training_30mins_data.pt'\n",
    "    model.load_state_dict(torch.load(fname))\n",
    "    #model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tracks:  499\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/63\n",
      "[0 0 0 3 3 0]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/182\n",
      "[0 0 2]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/52\n",
      "[3 3 0 0 3 2 2 0 0 2]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/88\n",
      "[1]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/335\n",
      "[0 0 0 0 0]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/442\n",
      "[1]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/206\n",
      "[2 3]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/447\n",
      "[3 3 3 3 1 1 3 1 3 3]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/436\n",
      "[1 3 1 2 1 3 2 2 3]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/163\n",
      "[2 3 2 2 2]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/15\n",
      "[0 0 0 0 2 0 0 0 0 0]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/257\n",
      "[3 0 2 3 2 3 0 2 3 2]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/169\n",
      "[2 2 3 2 2]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/162\n",
      "[1 3 1 3 3 1]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/38\n",
      "[0 0 0 2 0 2 0 0 0 2]\n",
      "processing track: /media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/124\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'frame is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-795e2aed28d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"processing track:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     predictions, confidence = load_training_data_run_prediction(selected_track, \n\u001b[0m\u001b[1;32m     13\u001b[0m                                                                  \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                                  device)\n",
      "\u001b[0;32m<ipython-input-61-a1d2a2c16606>\u001b[0m in \u001b[0;36mload_training_data_run_prediction\u001b[0;34m(fname_track, model, device, recompute)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m#fname_formated = os.path.join(fname_track,\"data_formated.npz\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m#if os.path.exists(fname_formated)==False:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_proceprocess_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname_track\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;31m#test_data = torch.from_numpy(all_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-a1d2a2c16606>\u001b[0m in \u001b[0;36mcnn_proceprocess_directory\u001b[0;34m(root_dir, save_formated_data)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mframe_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'frame is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "######### PREDICT ON TEST DATA ##########\n",
    "#########################################\n",
    "root_dir = '/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/'\n",
    "\n",
    "selected_tracks = glob.glob(root_dir+\"*\")\n",
    "print (\"# tracks: \", len(selected_tracks))\n",
    "for selected_track in selected_tracks:\n",
    "    #fname = +str(selected_track)+'/'\n",
    "    print (\"processing track:\", selected_track)\n",
    "\n",
    "    predictions, confidence = load_training_data_run_prediction(selected_track, \n",
    "                                                                 model,\n",
    "                                                                 device)\n",
    "    print (predictions[:10])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "######### COMBINE ALL PREDICTIONS INTO SINGLE FILE ######\n",
    "#########################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main animal  female\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########### PLOT RESULTS ###############\n",
    "########################################\n",
    "    \n",
    "plot_bars(predictions, confidence, test_data)\n",
    "\n",
    "\n",
    "\n",
    "# #(ctr, ids, classes, logits) = predict_cnn2(x_test, y_test)\n",
    "  \n",
    "# classes = np.hstack(classes)\n",
    "# print (\"classes: \", classes)\n",
    "\n",
    "# np.savez(root_dir+selected_output+'/classification_output.npz',\n",
    "#          track_id=selected_track,\n",
    "#          classes=predictions,\n",
    "#          confidence=confidence,\n",
    "#          )\n",
    "\n",
    "\n",
    "# print ('done')\n",
    "# REVIEW OUTPUT\n",
    "\n",
    "# thresh = 0.8\n",
    "# idx = np.where(confidence>thresh)[0]\n",
    "# a, b = np.unique(predictions[idx], return_counts=True)\n",
    "# if a.shape[0]>0:\n",
    "#     print (\"ids: \", a, \" counts: \", b)\n",
    "#     animal_best = a[np.argmax(b)]\n",
    "#     highest = np.max(b)/predictions[idx].shape[0]\n",
    "#     print ('Best animal predicted: ', animal_best, \"  purity: \", highest, \n",
    "#            \" # total frames: \", predictions.shape[0],\n",
    "#           \" # frames > threshold: \", idx.shape[0])\n",
    "#     #print (predictions[:10])\n",
    "# else:\n",
    "#     print(\"no images over threhsold\")\n",
    "\n",
    "# for k in range(4):\n",
    "#     ax=plt.subplot(2,2,k+1)\n",
    "#     try:\n",
    "#         idx = np.random.choice(np.arange(test_data.shape[0]))\n",
    "#         plt.imshow(test_data[idx].squeeze().cpu().detach().numpy().transpose(1,2,0))\n",
    "#     except:\n",
    "#         pass\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 2, 3]), array([ 1, 31, 47]))\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(c>0.9)[0]\n",
    "\n",
    "print (np.unique(p[idx], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/media/cat/7e3d5af3-7d7b-424d-bdd5-eb995a4a0c62/dan/cohort1/march_9/2020-3-9_12_14_22_815059_compressed/cnn_output_10mins/0/frame_0000374_id_0.npz')\n",
    "frame = data['frame']\n",
    "print (frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
